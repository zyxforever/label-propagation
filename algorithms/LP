import numpy as np
from scipy.spatial.distance import pdist, squareform
import math
import random
import scipy.io
from collections import Counter
from scipy.spatial.distance import cdist
from scipy.linalg import fractional_matrix_power
from sklearn.metrics.cluster import normalized_mutual_info_score as nmi,adjusted_rand_score as ari
from sklearn.neighbors import kneighbors_graph
import scipy.sparse as sp
from sklearn.metrics import accuracy_score as acc


n_labeled=1000
#不平衡比率
# p=[0.01,0.03,0.05,0.07,0.1,0.1,0.13,0.15,0.17,0.19]
p=[0.002,0.02,0.04,0.06,0.08,0.12,0.14,0.16,0.18,0.198]
# p=[0.1,0.3,0.6]

# print(sum(p))
# p=[15,25,35,45,55,65,75,85,95,100]
# p=[i/sum(p) for i in p]
# print(p)
n_iter = 10
# c=10
# c=3

def extract_data(X, Y, l):
    N_X = np.c_[X, Y]
    # print(l)
    # print(N_X[:, X.shape[1]])
    ll = np.where(N_X[:, X.shape[1]] == l)[0]
    random.shuffle(ll)
    # print(ll)
    # print(ll)
    # print(type(ll))
    # print(X[ll])
    # l_X = N_X[(N_X[:, X.shape[1]] == l)]
    # print(l_X)

    return ll
def over_sample(Dist,m,l):
    n=len(l)
    l1 = []
    flag = True

    # print(len(sortdist))

    while len(l1) < m-n:

        sum=len(l1)
        # print('l',l)
        dist=np.sort(Dist,axis=1)[l,1:5]
        dist1=dist.ravel()
        dist_idx=np.argsort(Dist,axis=1)[l,1:5].ravel()
        sortdist=np.sort(dist.ravel())

        if flag:
            temp=list(dist[:,1])
            mid=temp[int(len(temp)/2)]
            s=[np.mean(dist[:,1])*0.2+min(dist[:,1]),np.mean(dist[:,1]),mid]
            # if np.mean(dist[:,1])*0.2+min(dist[:,1])>np.mean(dist[:,1]):
            #     bounds=np.mean(dist[:,1])
            #     print('junzhi',bounds)
            # else:
            #     bounds=np.mean(dist[:,1])*0.2+min(dist[:,1])
            #     print('hecheng',bounds)
            bounds=min(s)
            # if min(s)==s[1]:
            #     print('hecheng',min(s))
            # elif min(s)==s[2]:
            #     print('junzhi',min(s))
            # else:
            #     print('mid',min(s))


        # print(bounds)
        flag = True
        k=0
        for i in range(len(sortdist)):

            if dist1[i]<=bounds and dist_idx[i] not in l1 and len(l1)<m-n:
                l1.append(dist_idx[i])
                k+=1
            if k>5:
                break
        # print(l1)
        # print('len', len(l1))
        if sum==len(l1):
            flag=False
            # bounds=up_bounds
            bounds=bounds*1.2
            # bounds=sortdist[sum+10]
        # print(bounds)
        l=list(set(l).union(set(l1)))
        # print('l',len(l))
    # print(len(l1))
    return l1
def class_balance_data(shuffle=True):

    #读取特征矩阵
    data = scipy.io.loadmat('data_PenDigits_bai.mat')
    # data = scipy.io.loadmat('data_USPS_4.mat')
    # data = scipy.io.loadmat('data_USPS_bai.mat')
    # data = scipy.io.loadmat('data_MNIST_bai.mat')
    # data = scipy.io.loadmat('iris_3.mat')
    fea = data['fea']
    gt = data['gt']

    # data = scipy.io.loadmat('data_MNIST10k_bai.mat')
    # fea = data['data']
    # gt = data['labels']
    # print(fea[1])
    # idx = np.random.choice(70000, size=10000, replace=False)
    # fea = fea[idx] if shuffle else fea
    # gt = gt[idx] if shuffle else gt
    gt=np.squeeze(gt).tolist()
    g_t=list(np.unique(gt))
    c=len(g_t)
    p=int(n_labeled/c)
    random.shuffle(g_t)
    # 获取特征矩阵 行 列大小
    N = fea.shape[0]
    M = fea.shape[1]
    l=[]
    for i in g_t:
        l1=extract_data(fea,gt,i)
        l1=l1[:p]
        l.extend(l1)

    X1=fea[l]
    gt=np.array(gt)
    Y1=gt[l]
    print('数据集：', Counter((Y1).flatten()))
    # print(X1)
    # print(Y1)
    fea=fea[np.setdiff1d(np.arange(N),l)]
    gt=gt[np.setdiff1d(np.arange(N),l)]
    N=fea.shape[0]
    #随机抽样
    idx_rand = np.random.choice(N, size=N, replace=False)
    X2=fea[idx_rand] if shuffle else fea
    Y2=gt[idx_rand] if shuffle else gt
    X=np.r_[X1,X2]
    Y=np.r_[Y1,Y2]
    Y=np.squeeze(Y)
    N = X.shape[0]
    M = X.shape[1]
    print('数据集：', Counter((Y).flatten()))
    # print(X.shape)
    # print(Y.shape)
    return X,Y,N,M
def class_imblance_data(shuffle=True):
    # 读取特征矩阵
    data = scipy.io.loadmat('data_PenDigits_bai.mat')
    # data = scipy.io.loadmat('data_MNIST_bai.mat')
    # data = scipy.io.loadmat('data_USPS_bai.mat')
    # data = scipy.io.loadmat('iris_3.mat')
    fea = data['fea']
    gt = data['gt']
    # data = scipy.io.loadmat('data_MNIST10k_bai.mat')
    # fea = data['data']
    # gt = data['labels']




    g_t = np.unique(gt).tolist()
    gt = np.squeeze(gt).tolist()


    # 获取特征矩阵 行 列大小
    N = fea.shape[0]
    M = fea.shape[1]
    random.shuffle(g_t)
    l = []
    ll = []

    for i in range(len(g_t)):
        l1 = extract_data(fea, gt, g_t[i])
        l1 = list(l1[:int(p[i] * n_labeled)])
        ll.append(l1)
        l.extend(l1)
    X1 = fea[l]
    gt = np.array(gt)
    Y1 = gt[l]
    print('数据集：', Counter((Y1).flatten()))
    # print(X1)
    # print(Y1)
    fea = fea[np.setdiff1d(np.arange(N), l)]
    gt = gt[np.setdiff1d(np.arange(N), l)]
    N = fea.shape[0]
    idx_rand = np.random.choice(N , size=N , replace=False)
    X2 = fea[idx_rand] if shuffle else fea
    Y2 = gt[idx_rand] if shuffle else gt
    X = np.r_[X1, X2]
    Y = np.r_[Y1, Y2]
    Y = np.squeeze(Y)
    N = X.shape[0]
    M = X.shape[1]
    # print(X)
    # print(Y)
    return X, Y, N, M
def imblance_improve_data(shuffle=True):
    # 读取特征矩阵
    data = scipy.io.loadmat('data_PenDigits_bai.mat')
    # data = scipy.io.loadmat('data_MNIST_bai.mat')
    # data = scipy.io.loadmat('data_USPS_bai.mat')
    # data = scipy.io.loadmat('iris_3.mat')

    fea = data['fea']
    gt = data['gt']
    # data = scipy.io.loadmat('data_MNIST10k_bai.mat')
    # fea = data['data']
    # gt = data['labels']

    g_t=np.unique(gt).tolist()
    gt = np.squeeze(gt).tolist()


    # 获取特征矩阵 行 列大小
    N = fea.shape[0]
    M = fea.shape[1]
    random.shuffle(g_t)
    # g_t = [2, 4, 1, 3, 5, 6, 7, 8, 9, 10]
    l = []
    ll=[]

    m = int(0.1 * n_labeled)
    for i in range(len(g_t)):
        l1 = extract_data(fea, gt, g_t[i])
        random.shuffle(l1)
        l1 = list(l1[:int(p[i]*n_labeled)])
        ll.append(l1)
        l.extend(l1)
    X1 = fea[l]
    gt = np.array(gt)
    Y1 = gt[l]
    print('数据集：', Counter((Y1).flatten()))

    l2=[]

    #欠采样
    for i in range(5,10):
        q=random.sample(ll[i],m)
        # q=ll[i]
        l2.extend(q)
    gt = np.array(gt)
    Y1 = gt[l2]
    # #欠采样
    # q=random.sample(ll[2],m)
    # l2.extend(q)
    # gt = np.array(gt)
    # Y1 = gt[l2]

    #计算距离矩阵
    print('距离矩阵计算开始')
    Dist1 = cdist(fea, fea, 'euclidean')

    # Dist1 = Dist1 / np.max(Dist1)
    #
    # Dist2 = cdist(fea, fea, 'cosine')
    # print(Dist2)
    # Dist2 = Dist2 / np.max(Dist2)
    # Dist2 =Dist2/10
    # Dist3 = cdist(fea,fea,'mahalanobis')
    # # sum3 = np.sum(Dist3, axis=1)
    # # Dist3 = Dist3 / sum3[:, None]
    #
    # Dist = 0.8*Dist1 +0.2*Dist2
    Dist = Dist1
    # print(Dist)
    print('距离矩阵计算完成')
    #过采样
    for i in range(0,5):
        q=over_sample(Dist,m,ll[i])
        # print(g_t[i])
        # print(len(list(gt[q])))
        # print(list(gt[q]))
        print(predict(list([g_t[i]] * (len(q))),list(gt[q])))
        ll[i].extend(q)
        l2.extend(ll[i])
        Y2 = np.array(list([g_t[i]] * (m)))
        Y1 = np.r_[Y1, Y2]
    # q = over_sample(Dist, m, ll[0])
    # print(predict(list([g_t[i]] * (len(q))), list(gt[q])))
    # ll[i].extend(q)
    # l2.extend(ll[i])
    # Y2 = np.array(list([g_t[i]] * (m)))
    # Y1 = np.r_[Y1, Y2]
    X1 = fea[l2]


    print('数据集：', Counter((Y1).flatten()))
    fea = fea[np.setdiff1d(np.arange(N), l)]
    gt = gt[np.setdiff1d(np.arange(N), l)]
    N = fea.shape[0]

    idx_rand = np.random.choice(N, size=N, replace=False)
    X2 = fea[idx_rand] if shuffle else fea
    Y2 = gt[idx_rand] if shuffle else gt
    X = np.r_[X1, X2]
    Y = np.r_[Y1, Y2]
    Y = np.squeeze(Y)
    N = X.shape[0]
    M = X.shape[1]
    # print(X.shape)
    # print(Y.shape)
    # print('数据集：', Counter((Y).flatten()))
    return X, Y, N, M


def predict(Y_predict,Y_true):
    sum=0
    tol=len(Y_predict)
    for i in range(tol):
        if Y_predict[i]==Y_true[i]:
            sum+=1
    print('predict_acc_{}={}'.format(Y_predict[0],sum/tol))
def DLP_matrix(X,k):
    # X=X/255
    Dist = cdist(X, X, 'euclidean')
    # sigma = np.mean(Dist)
    sigma = np.mean(Dist, axis=1)
    print('dm=', Dist)
    rbf = lambda x, sigma: math.exp((-x) / (2 * (math.pow(sigma, 2))))
    W = np.zeros([X.shape[0], X.shape[0]])

    vfunc = np.vectorize(rbf)

    sortedDist = np.argsort(Dist)
    sortedDist = sortedDist[:, 1:k + 1]

    print('计算权重矩阵')
    for i in range(X.shape[0]):
        W[i, sortedDist[i]] = vfunc(Dist[i, sortedDist[i]], sigma[i])

    print('权重矩阵计算结束')
    print('W1', W[0])
    print('W1sum', sum(W[0]))
    np.fill_diagonal(W, 0)
    sum_lines = np.sum(W, axis=1)
    D = np.diag(sum_lines)

    # D = fractional_matrix_power(D, -1)
    # # I=np.eye(X.shape[0])
    # # S = I-np.dot(D, W)
    # S = np.dot(D, W)
    # S = (S.T + S) / 2
    # print(S)
    # print(S[0])
    # print(sum(S[0]))
    D = fractional_matrix_power(D, -0.5)
    S = np.dot(np.dot(D, W), D)
    return S
    # Dist = cdist(X, X, 'euclidean')
    # # print(Dist)
    # m=X.shape[0]
    # k_idx = np.zeros([m, k])
    # for i in range(m):
    #     topk = np.argsort(Dist[i])[1:k + 1]  # 从1开始，是因为最小那个距离是它本身, 返回最小的k个的索引
    #     k_idx[i] = k_idx[i] + topk
    # k_idx = k_idx.astype(np.int32)
    # rbf = lambda x, sigma: math.exp((-x) / (2 * (math.pow(sigma, 2))))
    # vfunc = np.vectorize(rbf)
    # w = np.zeros([m, m])
    # for i in range(m):
    #     N_x=Dist[i][k_idx[i]]
    #     sigma=np.mean(N_x)
    #     # print(N_x)
    #     # print('N_x',N_x.shape)
    #     weight=vfunc(N_x,sigma)
    #     # print('weight',weight)
    #     l=weight/np.sum(weight)
    #     # print('l',l)
    #     # print(l.shape)
    #     w[i, k_idx[i]] = l
    # print('w',np.sum(w,axis=1))
    # w=normalize(w)
    # return w

def normalize(mx):
    """Row-normalize sparse matrix"""
    rowsum = np.array(mx.sum(1))
    r_inv = np.power(rowsum, -1).flatten()
    r_inv[np.isinf(r_inv)] = 0.
    r_mat_inv = sp.diags(r_inv)
    mx = r_mat_inv.dot(mx)
    return mx
def compute_knn(X,k):
    adj = kneighbors_graph(X, k,mode='connectivity', include_self=True)
    # print(adj)
    # print(type(adj))
    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)
    adj = normalize(adj + sp.eye(adj.shape[0]))
    #adj = sparse_mx_to_torch_sparse_tensor(adj)
    return adj.toarray()
def SIS_matrix(X,Y):
    l1 = np.unique(Y).tolist()
    k = int(len(l1) * 1.5)
    # k=15
    dist = pdist(X, 'euclidean')  # 获得距离矩阵
    dist = squareform(dist)  # 转化为方阵
    m = dist.shape[0]
    # print(m)
    k_idx = np.zeros([m, k])
    for i in range(m):
        topk = np.argsort(dist[i])[1:k + 1]  # 从1开始，是因为最小那个距离是它本身, 返回最小的k个的索引
        k_idx[i] = k_idx[i] + topk
    k_idx=k_idx.astype(np.int32)
    w = np.zeros([m, m])
    for i in range(m):
        Q_x = X[k_idx[i]]
        # print('Q_x',Q_x)
        # print('Q_x',Q_x.shape)
        xi = X[i]
        xi = np.tile(xi, (k, 1))
        # print('xi',xi)
        C = np.dot((xi - Q_x), (xi - Q_x).T)
        # print('C',C)
        C = C + np.eye(k) * (1e-3) * np.trace(C)
        # print('C', C)
        C_inv = np.linalg.pinv(C)
        # print('C_inv',C_inv)
        # print(np.dot(C,C_inv))
        l=np.sum(C_inv, axis=0) / np.sum(C_inv)
        # print(l)
        l=np.maximum(l,0)
        l=l/np.sum(l)
        w[i, k_idx[i]] = l
    return w
def weight_matrix(X):
    sigma = 0.1
    # X=X/255
    dm = cdist(X, X, 'euclidean')
    # sigma = np.mean(dm)
    # print(sigma)
    # print('dm=', dm)
    rbf = lambda x, sigma: math.exp((-x) / (2 * (math.pow(sigma, 2))))
    # print(rbf)
    vfunc = np.vectorize(rbf)
    # print(vfunc)

    W = vfunc(dm, sigma)
    np.fill_diagonal(W, 0)
    # print('w=',W)
    sum_lines = np.sum(W, axis=1)
    D = np.diag(sum_lines)
    # print('d=',D)
    D = fractional_matrix_power(D, -0.5)
    S = np.dot(np.dot(D, W), D)
    # print(S)
    return S
def GTAM(X,Y,n):
    labels_list = len(np.unique(Y))
    X = X / 255
    # 将标签向量lx1通过比较张成对应列为1的矩阵 lxc大小
    # print((Y[:n_labeled, None] == np.arange(labels_list)).astype(float))
    # 拼接无标签数据扩充至nxc大小
    Y0 = (Y[:n_labeled, None] == np.arange(labels_list)).astype(float)
    Y = np.concatenate((Y0, np.zeros((n - n_labeled, labels_list))))
    print('Y',Y)
    sigma = 0.1
    dm = cdist(X, X, 'euclidean')
    print(dm)
    rbf = lambda x, sigma: math.exp((-x) / (2 * (math.pow(sigma, 2))))
    vfunc = np.vectorize(rbf)
    W = vfunc(dm, sigma)
    np.fill_diagonal(W, 0)
    print('w=',W)
    sum_lines = np.sum(W, axis=1)
    D1 = np.diag(sum_lines)
    print(D1)
    D = fractional_matrix_power(D1, -0.5)
    L = np.dot(np.dot(D, W), D)
    print('L',L)
    def calculate_v(Y,D):
        sum=0

        one=np.ones([Y.shape[0],1])
        for i in range(Y.shape[1]):
            sum+=np.multiply(Y[:,i],np.dot(D,one))/np.dot(Y[:,i].T,np.dot(D,one))
        return sum

    I = np.eye(X.shape[0])
    P=np.linalg.inv(L/(99+I))
    A=np.dot(P.T,np.dot(L,P))+np.dot((P.T-I),(P-I))
    X_l=list(range(0,n_labeled))
    X_n=list(range(0,X.shape[0]))
    X_u=[i for i in X_n if i not in X_l]
    print('label',X_l)
    print('unlabel',X_u)
    print('开始循环')
    for i in range(X.shape[0]-n_labeled):
        v = calculate_v(Y, D1)
        V = np.eye(X.shape[0]) * v
        Z=np.dot(V,Y)
        ZQ=np.dot((A+A.T),Z)
        ind_min=np.argmin(ZQ[X_u])
        ind_min_src = np.unravel_index(ind_min, ZQ[X_u].shape)
        Y[X_u[ind_min_src[0]],ind_min_src[1]]=1
        X_l.append(X_u[ind_min_src[0]])
        X_u.remove(X_u[ind_min_src[0]])
        print(len(X_u))
    return Y

def progatation(S,Y,n_labeled,n,n_iter):
    alpha = 0.99
    labels_list = len(np.unique(Y))
    # 将标签向量lx1通过比较张成对应列为1的矩阵 lxc大小
    # print((Y[:n_labeled, None] == np.arange(labels_list)).astype(float))
    # 拼接无标签数据扩充至nxc大小
    Y0=(Y[:n_labeled, None] == np.arange(labels_list)).astype(float)
    Y_input = np.concatenate((Y0, np.zeros((n - n_labeled, labels_list))))
    # print(Y_input)
    # print(S.shape)
    # print(Y_input.shape)
    F = np.dot(S, Y_input) * alpha + (1 - alpha) * Y_input
    for t in range(n_iter):
        # print(t)
        F = np.dot(S, F) * alpha + (1 - alpha) * Y_input
    return F
def DLP_progatation(S,X,Y,n_labeled,n,n_iter):
    alpha = 0.05
    lamda=0.1
    # X=X/255
    p=weight_matrix(X)

    labels_list = len(np.unique(Y))
    # 将标签向量lx1通过比较张成对应列为1的矩阵 lxc大小
    # print((Y[:n_labeled, None] == np.arange(labels_list)).astype(float))
    # 拼接无标签数据扩充至nxc大小
    Y0 = (Y[:n_labeled, None] == np.arange(labels_list)).astype(float)
    Y = np.concatenate((Y0, np.zeros((n - n_labeled, labels_list))))
    Y=np.dot(p,Y)
    P = np.dot(np.dot(S, (p + alpha * (np.dot(Y, Y.T)))), S.T) + lamda * np.eye(n)
    for t in range(n_iter):
        print(t)
        Y=np.dot(P,Y)
        print(Y[:10])
        Y=np.r_[Y0,Y[n_labeled:,:]]

        P=np.dot(np.dot(S, (P+alpha*(np.dot(Y,Y.T)))),S.T)+lamda*np.eye(n)
    return Y
#预测结果
def predict_result(predict_labels,true_labels,n_labeled):
    #acc
    sum=0
    tol=len(predict_labels)
    for i in range(tol):
        if predict_labels[i]==true_labels[n_labeled+i]:
            sum+=1
    print('predict_acc={}'.format(sum/tol))
    #nmi,ari
    true_labels=true_labels[n_labeled:]
    predict_nmi = nmi(true_labels, predict_labels)
    predict_ari = ari(true_labels, predict_labels)
    print('predict_nmi={}'.format(predict_nmi))
    print('predict_ari={}'.format(predict_ari))

def start():
    for i in range(10):
        print('类平衡')
        X, Y, n, m = class_balance_data()
        # print(X.shape)
        # S1 = weight_matrix(X)
        # S1=SIS_matrix(X,Y)
        # S1 = compute_knn(X, 20)
        S1=DLP_matrix(X,20)
        print('传播矩阵计算结束')
        # print(S1.shape)
        # F = progatation(S1, Y, n_labeled, n, n_iter)
        F = DLP_progatation(S1,X, Y, n_labeled, n, n_iter)
        # F=GTAM(X,Y,n)
        Y_result = np.zeros(n - n_labeled)

        for i in range(n - n_labeled):
            Y_result[i] = np.argmax(F[i + n_labeled])
        # print(Y_result)
        Y_p=np.r_[Y[:n_labeled],Y_result]
        print('预测：', Counter((Y_result).flatten()))
        print('真值：', Counter((Y).flatten()))
        print("ACC NMI ARI")
        print("{:0.4f}  {:0.4f}  {:0.4f}".format(acc(Y_p, Y), nmi(Y_p, Y), ari(Y_p, Y)))

        # print('类不平衡')
        # X, Y, n, m = class_imblance_data()
        #
        # # S2 = weight_matrix(X)
        # # S2 = SIS_matrix(X, Y)
        # # S2 = compute_knn(X, 20)
        # S1 = DLP_matrix(X, 20)
        # F = DLP_progatation(S1,X, Y, n_labeled, n, n_iter)
        # # F = progatation(S2, Y, n_labeled, n, n_iter)
        # Y_result = np.zeros(n - n_labeled)
        #
        # for i in range(n - n_labeled):
        #     Y_result[i] = np.argmax(F[i + n_labeled])
        # Y_p=np.r_[Y[:n_labeled],Y_result]
        # print('预测：', Counter((Y_result).flatten()))
        # print('真值：', Counter((Y).flatten()))
        # # predict_result(Y_result, Y, n_labeled)
        # print("ACC NMI ARI")
        # print("{:0.4f}  {:0.4f}  {:0.4f}".format(acc(Y_p, Y), nmi(Y_p, Y), ari(Y_p, Y)))
        #
        #
        #
        # print('类不平衡改进')
        # X, Y, n, m = imblance_improve_data()
        # # S2=weight_matrix(X)
        # # S2 = compute_knn(X, 20)
        # # S2 = SIS_matrix(X, Y)
        # S1 = DLP_matrix(X, 20)
        # F = DLP_progatation(S1, X,Y, n_labeled, n, n_iter)
        # # F = progatation(S2, Y, n_labeled, n, n_iter)
        # Y_result = np.zeros(n - n_labeled)
        #
        # for i in range(n - n_labeled):
        #     Y_result[i] = np.argmax(F[i + n_labeled])
        # Y_p = np.r_[Y[:n_labeled], Y_result]
        # print('预测：', Counter((Y_result).flatten()))
        # print('真值：', Counter((Y).flatten()))
        # print("ACC NMI ARI")
        # print("{:0.4f}  {:0.4f}  {:0.4f}".format(acc(Y_p, Y), nmi(Y_p, Y), ari(Y_p, Y)))
        # # predict_result(Y_result, Y, n_labeled)



if __name__ == '__main__':
    start()
